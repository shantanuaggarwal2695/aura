# Hume.ai API Configuration
HUME_API_KEY=MeRAKQjlPi5ggUJpUsOvjdR9qLrYh26Zku5q7rW0mqU9ikgZ
HUME_API_URL=https://api.hume.ai

# LLM Configuration (supports Gemini, OpenAI-compatible, and Hugging Face)
# Provider options: "gemini", "openai_compatible", "huggingface"
LLM_PROVIDER=gemini

# For Gemini (Google ADK)
GOOGLE_ADK_API_KEY=AIzaSyCCq1lpXJ0MI8xU2EEM9Sz86ACvYKIO4Wg
GOOGLE_ADK_API_URL=https://generativelanguage.googleapis.com/v1beta
GOOGLE_ADK_MODEL_NAME=gemini-2.5-flash-lite
# Available Gemini models:
# - gemini-2.5-flash-lite (latest, recommended, fast and efficient)
# - gemini-2.5-flash (latest flash model)
# - gemini-1.5-flash (fast and efficient)
# - gemini-1.5-pro (more capable, slower)
# - gemini-1.5-pro-latest (latest pro version)
# - gemini-1.5-pro-vision (multimodal: text + images)
GOOGLE_ADK_SYSTEM_INSTRUCTION=You are a helpful, friendly, and knowledgeable AI assistant. You provide clear, concise, and accurate responses to user questions. Be conversational and engaging while maintaining professionalism.

# For OpenAI-compatible providers (Ollama, vLLM, Together AI, etc.)
# LLM_PROVIDER=openai_compatible
# LLM_API_KEY=  # Optional, not needed for local Ollama
# LLM_API_URL=http://localhost:11434/v1  # Ollama default
# LLM_MODEL_NAME=llama3.2  # or mistral, codellama, etc.
# LLM_SYSTEM_INSTRUCTION=You are a helpful, friendly, and knowledgeable AI assistant.

# For Hugging Face
# LLM_PROVIDER=huggingface
# LLM_API_KEY=your_huggingface_token_here
# LLM_API_URL=https://api-inference.huggingface.co
# LLM_MODEL_NAME=meta-llama/Llama-3.2-3B-Instruct
# LLM_SYSTEM_INSTRUCTION=You are a helpful, friendly, and knowledgeable AI assistant.

# Unified LLM config (overrides provider-specific configs if set)
# LLM_API_KEY=
# LLM_API_URL=
# LLM_MODEL_NAME=
# LLM_SYSTEM_INSTRUCTION=

# Application Configuration
DEBUG=True
LOG_LEVEL=INFO
